<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en">

<head>
    <meta charset="utf-8">
    <title> AI-Benchmark </title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css?family=Raleway:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,700italic,400italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i	" rel="stylesheet"> 
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <script src="js/modernizr.js"></script>
    <meta name="viewport" content="width=device-width">

	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118781498-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-118781498-1');
	</script>
    
</head>

<body data-spy="scroll" data-offset="0" data-target="#navbar-main" style="background-image: none;">

<nav>
	<ul class="left_bar">
		<a href="index.html"> <img src="assets/img/splash.png"> </a>
	</ul>
	<ul class="middle_bar">
		<a href="index.html"> <li> BENCHMARK </li></a>
		<a href="ranking.html"> <li> RANKING </li></a>
		<a href="news.html"> <li> NEWS </li></a>
		<a href="tests.html"> <li> AI-TESTS </li></a>
	</ul>
	<ul class="right_bar">
		<a href="download.html"> <img style="width: 7.5vw; margin-top: 1.07vw; position: fixed; margin-left: -9.5vw;" src="assets/img/download.png"> </a>
		<a href="research.html"> <li style="color: #e94f70; font-size: 0.8vw; font-weight: 600;"> RESEARCH &nbsp; <img src="assets/img/goto.png"> </li></a>
		<a href="about.html" style="font-size: 1.0vw;"> <li> ABOUT </li></a>
	</ul>
</nav>

<div id="nav_mobile">
	<ul class="middle_bar">
		<a href="index.html"> <li> BENCHMARK </li></a>
		<a href="news.html"> <li> NEWS </li></a>
		<a href="ranking.html"> <li> RANKING </li></a>
		<a href="tests.html"> <li> AI-TESTS </li></a>
		<a href="research.html" > <li style="color: #e94f70; font-size: 1.57vw; font-weight: 600; margin-left: 1.2vw;"> RESEARCH &nbsp; <img style="width: 1.2vw;" src="assets/img/goto.png"> </li></a>
		<a href="download.html"> <img style="width: 11.2vw; padding-left: 3.6vw; vertical-align: middle;" src="assets/img/download.png"> </a>
	</ul>
	
</div>

<div id="news">

<h1 class="title3" style="word-spacing: 0.2vw;"> <span style="color: #ea1d6f;"> AI Benchmark for Windows, Linux and macOS: &nbsp;<span style="color: #178ed2;">Let the AI Games Begin...</span></h1>

<h1 class="paragraph">While Machine Learning is already a mature field, for many years it was lacking a professional, accurate and lightweight tool for measuring AI performance of various hardware used for training and inference with ML algorithms. Today we are making a step forward towards standardizing the benchmarking of AI-related silicon, and present a new standard for all-round performance evaluation of hardware platforms capable of running machine and deep learning models.
</h1>

<a href="ranking_cpus_and_gpus.html"><img style="width: 100%; margin-top: 0vw; margin-bottom: 1.2vw;" src="assets/img/ai_benchmark_for_desktops.png"></a>

<h1 class="paragraph_title" style="word-spacing: 0.2vw;"> Measuring AI Performance of Desktop CPUs and GPUs </h1>

<h1 class="paragraph">AI Benchmark Alpha is an open source python library for evaluating AI performance of various hardware platforms, including CPUs, GPUs and TPUs. The benchmark is relying on TensorFlow machine learning library, and is providing a precise and lightweight solution for assessing inference and training speed for key Deep Learning models. AI Benchmark is currently distributed as a <a href="https://pypi.org/project/ai-benchmark/" target="_blank" class="blue_link_underlined">Python pip package</a> and can be downloaded to any system running Windows, Linux or macOS.</h1>

<h1 class="paragraph">In total, AI Benchmark consists of <span style="font-weight: 400;">42 tests</span> and <span style="font-weight: 400;">19 sections</span> provided below: </br></br>

<span class="item-list">
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 1:</span> <span style="color: #ea1d6f;">MobileNet-V2</span>,&nbsp; <span style="color: #178ed2;"> Classification</span>,&nbsp; <a href="https://arxiv.org/pdf/1704.04861.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 2:</span> <span style="color: #ea1d6f;">Inception-V3</span>,&nbsp; <span style="color: #178ed2;"> Classification</span>,&nbsp; <a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 3:</span> <span style="color: #ea1d6f;">Inception-V4</span>,&nbsp; <span style="color: #178ed2;"> Classification</span>,&nbsp; <a href="https://arxiv.org/pdf/1602.07261.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 4:</span> <span style="color: #ea1d6f;">Inception-ResNet-V2</span>,&nbsp; <span style="color: #178ed2;"> Classification</span>,&nbsp; <a href="https://arxiv.org/pdf/1603.05027.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 5:</span> <span style="color: #ea1d6f;">ResNet-V2-50</span>,&nbsp; <span style="color: #178ed2;"> Classification</span>,&nbsp; <a href="https://arxiv.org/pdf/1603.05027.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 6:</span> <span style="color: #ea1d6f;">ResNet-V2-152</span>,&nbsp; <span style="color: #178ed2;"> Classification</span>,&nbsp; <a href="https://arxiv.org/pdf/1603.05027.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 7:</span> <span style="color: #ea1d6f;">VGG-16</span>,&nbsp; <span style="color: #178ed2;"> Classification</span>,&nbsp; <a href="https://arxiv.org/pdf/1409.1556.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 8:</span> <span style="color: #ea1d6f;">SRCNN 9-5-5</span>,&nbsp; <span style="color: #178ed2;"> Image-to-Image Mapping</span>,&nbsp; <a href="https://arxiv.org/pdf/1501.00092.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 9:</span> <span style="color: #ea1d6f;">VGG-19</span>,&nbsp; <span style="color: #178ed2;"> Image-to-Image Mapping</span>,&nbsp; <a href="https://arxiv.org/pdf/1511.04587.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 10:</span> <span style="color: #ea1d6f;">ResNet-SRGAN</span>,&nbsp; <span style="color: #178ed2;"> Image-to-Image Mapping</span>,&nbsp; <a href="https://arxiv.org/pdf/1609.04802.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 11:</span> <span style="color: #ea1d6f;">ResNet-DPED</span>,&nbsp; <span style="color: #178ed2;"> Image-to-Image Mapping</span>,&nbsp; <a href="http://people.ee.ethz.ch/~ihnatova/index.html" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 12:</span> <span style="color: #ea1d6f;">U-Net</span>,&nbsp; <span style="color: #178ed2;"> Image-to-Image Mapping</span>,&nbsp; <a href="https://arxiv.org/pdf/1505.04597.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 13:</span> <span style="color: #ea1d6f;">Nvidia-SPADE</span>,&nbsp; <span style="color: #178ed2;"> Image-to-Image Mapping</span>,&nbsp; <a href="https://arxiv.org/pdf/1903.07291.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 14:</span> <span style="color: #ea1d6f;">ICNet</span>,&nbsp; <span style="color: #178ed2;"> Image Segmentation</span>,&nbsp; <a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 15:</span> <span style="color: #ea1d6f;">PSPNet</span>,&nbsp; <span style="color: #178ed2;"> Image Segmentation</span>,&nbsp; <a href="https://arxiv.org/pdf/1612.01105.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 16:</span> <span style="color: #ea1d6f;">DeepLab</span>,&nbsp; <span style="color: #178ed2;"> Image Segmentation</span>,&nbsp; <a href="https://arxiv.org/pdf/1502.02734.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 17:</span> <span style="color: #ea1d6f;">Pixel-RNN</span>,&nbsp; <span style="color: #178ed2;"> Image Inpainting</span>,&nbsp; <a href="https://arxiv.org/pdf/1601.06759.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 18:</span> <span style="color: #ea1d6f;">LSTM</span>,&nbsp; <span style="color: #178ed2;"> Sentence Sentiment Analysis</span>,&nbsp; <a href="https://www.bioinf.jku.at/publications/older/2604.pdf" target="_blank" class="red_link">[paper]</a></br>
<span class="item">&#x25cf;&nbsp;</span> <span style="font-weight: 400; margin-right: 1.2vw;	">Section 19:</span> <span style="color: #ea1d6f;">GNMT</span>,&nbsp; <span style="color: #178ed2;"> Text Translation</span>,&nbsp; <a href="https://arxiv.org/pdf/1609.08144.pdf" target="_blank" class="red_link">[paper]</a></br>
</br>

The tests are covering all major Deep Learning tasks and architectures, and are therefore useful for researchers, developers, hardware vendors and end-users running AI applications on their devices. Additional information about setup for each test (input and batch sizes, test modes) can be found on the <a href="ranking_cpus_and_gpus_detailed.html" target="_blank" class="red_link_underlined">ranking page.</a></h1>

<h1 class="paragraph_title" style="word-spacing: 0.2vw;"> Installation Instructions - Short Guide</h1> 

<h1 class="paragraph">For those who are familiar with Deep Learning and Tensorflow:</br></br>

<span class="item-list">
<span class="item">1.&nbsp;</span> Install <a href="https://www.python.org/downloads/" target="_blank" class="blue_link_underlined">Python</a> and <a href="https://www.tensorflow.org/install/pip" target="_blank" class="blue_link_underlined">Tensorflow.</a></br>
<span class="item">2.&nbsp;</span> Install AI Benchmark with <a href="https://pypi.org/project/ai-benchmark/" target="_blank" class="blue_link_underlined">pip:</a>&nbsp; <span class="bash_code">pip install ai-benchmark</span></br>
<span class="item">3.&nbsp;</span> Use the following python code to run the benchmark:</br>

<div class="python_code">
	<span style="color: rgb(23, 142, 210);">from</span> ai_benchmark <span style="color: rgb(23, 142, 210);">import</span> <span style="color: rgb(234, 29, 111);">AIBenchmark</span></br>
	results = <span style="color: rgb(234, 29, 111);">AIBenchmark()</span><span style="color:rgb(255, 100, 100);">.run()</span>
</div>

<span class="item">Or, on Linux systems you can simply type <span class="bash_code">ai-benchmark</span> in the command line to start the tests.</br></span>
</span></br>

That's it, time to see the results!&nbsp; More information about library settings can be found <a href="https://pypi.org/project/ai-benchmark/" target="_blank" class="red_link_underlined">here.</a>
</h1>

<h1 class="paragraph_title" style="word-spacing: 0.2vw;"> Installation Instructions - Detailed Guide</h1> 

<h1 class="paragraph">
<span class="item-list">
<span class="item">1.&nbsp;</span> Download and install Python from <a href="https://www.python.org/downloads/" target="_blank" class="blue_link_underlined">python.org</a></br>
<span class="item"></span> If you are running Windows - add Python to the Windows Path using <a href="https://geek-university.com/python/add-python-to-the-windows-path/" target="_blank" class="blue_link_underlined">these instructions.</a></br>
<span class="item">2.&nbsp;</span> Install TensorFlow machine learning library:</br>
<span class="item">2.1.&nbsp;</span> If you <span style="font-weight: 400;">do not have Nvidia / AMD GPUs,</span> run <span class="bash_code">pip install tensorflow</span> from the command line.</br>
<span class="item">2.2.&nbsp;</span> If you want to check the performance of <span style="font-weight: 400;">Nvidia graphic cards:</span></br>
<span class="item">2.2.1.&nbsp;</span> Download and install <span style="font-weight: 400;">CUDA</span> from <a href="https://developer.nvidia.com/cuda-downloads" target="_blank" class="blue_link_underlined">Nvidia website.</a></br>
<span class="item">2.2.2.&nbsp;</span> <a href="https://developer.nvidia.com/cudnn" target="_blank" class="blue_link_underlined">Download</a> and <a href="https://docs.nvidia.com/deeplearning/sdk/cudnn-install/index.html" target="_blank" class="blue_link_underlined">install</a> <span style="font-weight: 400;">cuDNN.</span></br>
<span class="item">2.2.3.&nbsp;</span> Run <span class="bash_code">pip install tensorflow-gpu</span> from the command line.</br>
<span class="item">2.3.&nbsp;</span> If you want to check the performance of <span style="font-weight: 400;">AMD graphic cards:</span>&nbsp; follow <a href="https://gpuopen.com/rocm-tensorflow-1-8-release/" target="_blank" class="blue_link_underlined">these instructions.</a></br>
<span class="item">3.&nbsp;</span> Run <span class="bash_code">pip install ai-benchmark</span> from the command line.</br>
<span class="item">4.&nbsp;</span> Type <span class="bash_code">python</span> in the command line and run the following commands in the opened console:</br>

<div class="python_code">
	<span style="color: rgb(23, 142, 210);">from</span> ai_benchmark <span style="color: rgb(23, 142, 210);">import</span> <span style="color: rgb(234, 29, 111);">AIBenchmark</span></br>
	results = <span style="color: rgb(234, 29, 111);">AIBenchmark()</span><span style="color:rgb(255, 100, 100);">.run()</span>
</div>

<span class="item">Or, on Linux systems you can simply type <span class="bash_code">ai-benchmark</span> in the command line to start the tests.</br></span>
</span></br>
</h1>

<h1 class="paragraph_title"> Public Ranking </h1>

<h1 class="paragraph">On any system with TensorFlow framework, installing and running the benchmark takes just a couple of minutes, making it easy to assess the performance of various hardware configurations and software builds. By introducing a global ranking, we are targeting the following goals:</br></br>

<span class="item-list">
<span class="item">1.&nbsp;</span>&nbsp; Establishing an open standard for measuring the performance of AI-related hardware</br>
<span class="item">2.&nbsp;</span>&nbsp; Showing the relative speed of various hardware used for training / inference with Deep Learning</br>
<span class="item">3.&nbsp;</span>&nbsp; Showing the speed of training / inference for all major AI models on different hardware platforms</br>
<span class="item">4.&nbsp;</span>&nbsp; Comparing the performance of different drivers / configs, software platforms and framework builds</br>
<span class="item">5.&nbsp;</span>&nbsp; Connecting the dots between <a href="ranking.html" class="red_link_underlined">mobile</a> and conventional Deep Learning</br>
</span>

</h1>

<h1 class="paragraph">The current preliminary ranking is available <a href="ranking_cpus_and_gpus.html" class="red_link_underlined">here.</a> The ranking will be significantly updated in the next weeks.</h1>

<h1 class="paragraph_title"> Contacts  </h1>

<h1 class="paragraph">
The next AI Benchmark release is now in development, and we are happy to hear any feedback regarding the current version and suggestions for its improvement. For any proposals or additional information please contact <a href="mailto:andrey@vision.ee.ethz.ch" style="text-decoration: none; color: rgb(51, 51, 51);">andrey@vision.ee.ethz.ch.</a>
</h1>

<h1 class="meta">
	<p>28 June 2019 <span style="float: right;"><a href="mailto:andrey@vision.ee.ethz.ch" style="text-decoration: none; color: rgb(51, 51, 51);">Andrey Ignatov</a> | <a href="http://ai-benchmark.com" style="text-decoration: none;"><lh>AI Benchmark</lh><a></span></p>

</div>

<div id="about">
	<div id="content">
		<p >Copyright © 2018-2024 by A.I.</p>
		<p style="color: #ea1d6f">ETH Zurich, Switzerland</p>
	</div>
</div>

</body>

</html>
