<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html lang="en">

<head>
    <meta charset="utf-8">
    <title> AI-Benchmark </title>
    <link rel="stylesheet" href="style.css">
    <link href="https://fonts.googleapis.com/css?family=Raleway:400,700,400italic,700italic" rel="stylesheet" type="text/css">
    <link href="https://fonts.googleapis.com/css?family=Lato:400,700,700italic,400italic" rel="stylesheet" type="text/css">
    <link rel="shortcut icon" type="image/x-icon" href="favicon.ico" />
    <script src="js/modernizr.js"></script>
    <meta name="viewport" content="width=device-width">

	<script async src="https://www.googletagmanager.com/gtag/js?id=UA-118781498-1"></script>
	<script>
	  window.dataLayer = window.dataLayer || [];
	  function gtag(){dataLayer.push(arguments);}
	  gtag('js', new Date());

	  gtag('config', 'UA-118781498-1');
	</script>
    
</head>

<body data-spy="scroll" data-offset="0" data-target="#navbar-main" style="background-image: url(assets/img/2L_texture_blank.jpg);">

<nav>
	<ul class="left_bar">
		<a href="index.html"> <img src="assets/img/splash.png"> </a>
	</ul>
	<ul class="middle_bar">
		<a href="index.html"> <li> BENCHMARK </li></a>
		<a href="ranking.html"> <li> RANKING </li></a>
		<a href="#tests"> <li> AI-TESTS </li></a>
		<a href="faq.html"> <li> FAQ </li></a>
	</ul>
	<ul class="right_bar">
			<a href="https://play.google.com/store/apps/details?id=org.benchmark.demo" target="_blank"> <img style="width: 6.8vw; margin-top: 1.07vw; position: fixed; margin-left: -8vw;" src="assets/img/google_play.png"> </a>
		<a href="challenge.html" > <li style="color: #e94f70; font-size: 0.94vw;"> challenge <img src="assets/img/goto.png"> </li></a>
		<a href="about.html" style="font-size: 1.0vw;"> <li> ABOUT </li></a>
	</ul>
</nav>

<div id="nav_mobile">
	<ul class="middle_bar">
		<a href="index.html"> <li> BENCHMARK </li></a>
		<a href="ranking.html"> <li> RANKING </li></a>
		<a href="tests.html"> <li> AI-TESTS </li></a>
		<a href="faq.html"> <li> FAQ </li></a>
		<a href="challenge.html" > <li style="color: #e94f70; font-size: 1.57vw; margin-left: 1.2vw;"> challenge <img style="width: 1.2vw;" src="assets/img/goto.png"> </li></a>
	</ul>
</div>

<div id="tests">

<p>The benchmark consists of <span style="color: #ea1d6f;">9 Computer Vision AI tasks</span> performed by <span style="color: #ea1d6f;">9 separate Neural Networks</span> that are running on your smartphone. Considered networks comprise a broad range of architectures which allows to assess the performance and limits of various approaches used to solve AI problems.</p>

<!------------------------------ Task 1 ----------------------------->

<div class="task">

	<img class="img_style_left_1" src="assets/img/screen_1.jpg">
	
	<p class="title_class_1"><span class="title_class_task">Task 1:</span> &nbsp; <span class="title_class_name">Object Recognition / Classification 
	</p>
	<p class="desc_class_1"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">MobileNet - V1 &nbsp; | &nbsp; <span class="mode">CPU, NPU, DSP</p>
	<p class="desc_class_2"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">224 x 224 px</p>
	<p class="desc_class_2"><span class="desc_class_name">Accuracy on ImageNet:</span> &nbsp; <span class="desc_class_value">69.7 %</p>
	<p class="desc_class_3"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1704.04861.pdf" target="_blank">paper</a> / <a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet_v1.py" target="_blank">code</a></p>

	<p class="desc_class_4"> A very basic yet already powerful neural network that is able to recognize 1000 different object classes based on a single photo with an accuracy of ~70%. After quantization its size is less than 5Mb, which together with its low RAM consumption allows to lanch it on almost any currently existing smartphone.</p>

</div>

<!------------------------------ Task 2 ----------------------------->

<div class="task">

	<img class="img_style_right_1" src="assets/img/screen_2.jpg">
	
	<p class="title_class_l_1"><span class="title_class_task">Task 2:</span> &nbsp; <span class="title_class_name">Object Recognition / Classification </p>
	<p class="desc_class_l_1"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">Inception - V3 &nbsp; | &nbsp; <span class="mode">CPU, NPU, DSP</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">346 x 346 px</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Accuracy on ImageNet:</span> &nbsp; <span class="desc_class_value">78.0 %</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1512.00567.pdf" target="_blank">paper</a> / <a href="https://github.com/tensorflow/models/blob/master/research/slim/nets/inception_v3.py" target="_blank">code</a></p>

	<p class="desc_class_l_4"> Further extension of the previous network: now significantly more accurate, but at the expense of 4x larger size and tough computational requirements. As a clear bonus - can process images of higher resolutions, which allows more accurate recognition and smaller object detection.</p>

</div>

<!------------------------------ Task 3 ----------------------------->

<div class="task">

	<img class="img_style_left_2" src="assets/img/screen_3.jpg">
	
	<p class="title_class_1"><span class="title_class_task">Task 3:</span> &nbsp; <span class="title_class_name">Face Recognition </p>
	<p class="desc_class_1_2"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">Inception - Resnet - V1 &nbsp; | &nbsp; <span class="mode">CPU only</p>
	<p class="desc_class_2"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">512 x 512 px</p>
	<p class="desc_class_2"><span class="desc_class_name">LFW Score:</span> &nbsp; <span class="desc_class_value">0.987</p>
	<p class="desc_class_2"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1503.03832.pdf" target="_blank">paper</a> / <a href="https://github.com/davidsandberg/facenet/blob/master/src/models/inception_resnet_v1.py" target="_blank">code</a></p>

	<p class="desc_class_4_2"> This task probably doesn't need an introduction: based on the face photo you want to identify the person. This is done in the following way: for each face image, a neural network produces a small feature vector of size 128 that encodes the face and is invariant to its scaling, shifts and rotations. Then this vector is used to retrieve the most similar vector (and the respective identity) from your database that contains the same information about hundreds or millions of people. </p>

</div>

<!------------------------------ Task 4 ----------------------------->

<div class="task">

	<figure class="cd-image-container" style="float: right; margin-right: -0.1vw;">
		<img src="assets/img/screen_4a.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">Blurred</span>
		
		<div class="cd-resize-img">
			<img src="assets/img/screen_4b.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">Restored</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>
	
	
	<p class="title_class_l_1"><span class="title_class_task">Task 4:</span> &nbsp; <span class="title_class_name">Image Deblurring </p>
	<p class="desc_class_l_1_2"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">SRCNN 9-5-5 &nbsp; | &nbsp; <span class="mode">CPU, NPU, DSP</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">300 x 300 px</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Set-5 Score (x3):</span> &nbsp; <span class="desc_class_value">32.75 dB</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1501.00092.pdf" target="_blank">paper</a> / <a href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html" target="_blank">code</a></p>
	<p class="desc_class_l_4_2"> Remember taking blurry photos using your phone camera? So, this is the task: make them sharp again. In the simplest case, this kind of distortions is modeled by applying a Gaussian blur to uncorrupted images, and then trying to restore them back using a neural network. In  this task, blur is removed by one of the oldest, simplest and lightest neural networks - by SRCNN with only 3 convolutional layers, though in this case it still shows quite satisfactory results. </p>

</div>

<!------------------------------ Task 5 ----------------------------->

<div class="task">

	<figure class="cd-image-container image_style_3">
		<img src="assets/img/screen_5a.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">Zoomed</span>
		<div class="cd-resize-img">
			<img src="assets/img/screen_5b.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">Restored</span>
		</div>
		<span class="cd-handle cd-first"></span>
	</figure>
	
	<p class="title_class_1_3"><span class="title_class_task">Task 5:</span> &nbsp; <span class="title_class_name">Image  Super-Resolution</p>
	<p class="desc_class_1_3"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">VGG - 19 &nbsp; | &nbsp; <span class="mode">CPU, NPU, DSP</p>
	<p class="desc_class_2_3"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">192 x 192 px</p>
	<p class="desc_class_2_3"><span class="desc_class_name">Set-5 Score (x3):</span> &nbsp; <span class="desc_class_value">33.66 dB</p>
	<p class="desc_class_2_3"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1511.04587.pdf" target="_blank">paper</a> / <a href="https://github.com/Jongchan/tensorflow-vdsr" target="_blank">code</a></p>
	<p class="desc_class_4_3"> Have you ever zoomed you photos? Remember artifacts, lack of details and sharpness? Then you know this task from your own experience: make zoomed photos look as good as the original images. In this case, the network is trained to do an equivalent task: to restore the original photo given its downscaled (e.g. by factor of 4) version. Here we consider a deep VGG-19 network with 19 layers. While its performance is currently not amazing and it is not able to reconstruct high-frequency components, it is still an ideal solution for paintings and drawings: it makes them sharp but smooth. </p>

</div>

<!------------------------------ Task 6 ----------------------------->

<div class="task">

	<figure class="cd-image-container" style="float: right; margin-right: -0.1vw;">
		<img src="assets/img/screen_6a.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">Zoomed</span>
		
		<div class="cd-resize-img">
			<img src="assets/img/screen_6b.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">Restored</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>
	
	
	<p class="title_class_l_1"><span class="title_class_task">Task 6:</span> &nbsp; <span class="title_class_name">Image Super-Resolution </p>
	<p class="desc_class_l_1_2"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">SRGAN &nbsp; | &nbsp; <span class="mode">CPU only</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">512 x 512 px</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Set-5 Score (x4):</span> &nbsp; <span class="desc_class_value">29.40 dB</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1609.04802.pdf" target="_blank">paper</a> / <a href="https://github.com/tensorlayer/srgan" target="_blank">code</a></p>
	<p class="desc_class_l_4_2"> The same task, but with new tricks: what if we train our neural network using... another neural network? Yes, two network performing two tasks: network A is trying to solve the same super-resolution problem as above, but network B observes its results, tries to find there some drawbacks and then penalizes network A. Sounds cool? In fact it is cool: while this approach has its own issues, the produced results are often looking really amazing.</p>

</div>

<!------------------------------ Task 7 ----------------------------->

<div class="task">

	<figure class="cd-image-container" style="float: left; margin-left: -0.2vw;">
		<img src="assets/img/screen_7a.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">Original</span>
		<div class="cd-resize-img">
			<img src="assets/img/screen_7b.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">Segmented</span>
		</div>
		<span class="cd-handle cd-first"></span>
	</figure>
	
	<p class="title_class_1_3"><span class="title_class_task">Task 7:</span> &nbsp; <span class="title_class_name">Semantic Image Segmentation</p>
	<p class="desc_class_1_3"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">ICNet &nbsp; | &nbsp; <span class="mode">CPU only</p>
	<p class="desc_class_2_3"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">384 x 576 px</p>
	<p class="desc_class_2_3"><span class="desc_class_name">CityScapes (mIoU):</span> &nbsp; <span class="desc_class_value">69.5 %</p>
	<p class="desc_class_2_3"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1704.08545.pdf" target="_blank">paper</a> / <a href="https://github.com/hszhao/ICNet" target="_blank">code</a></p>
	<p class="desc_class_4_3"> Running Self-Driving algorithm on your phone? Yes, that's possible too, at least you can perform a substantial part of this task &ndash; detect 19 categories of objects (e.g. car, pedestrian, road, sky, etc.) based on the photo from the camera mounted inside the car. In the right image you can see the results of such pixel-size segmentation (each color correpsonds to each object class) for a quite recent ICNet network designed specifically for low-performance devices.</p>

</div>

<!------------------------------ Task 8 ----------------------------->

<div class="task">

	<figure class="cd-image-container image_style_4">
		<img src="assets/img/screen_8a.jpg" alt="Original Image">
		<span class="cd-image-label" data-type="original">Original</span>
		
		<div class="cd-resize-img">
			<img src="assets/img/screen_8b.jpg" alt="Modified Image">
			<span class="cd-image-label" data-type="modified">Enhanced</span>
		</div>
		
		<span class="cd-handle cd-first"></span>
	</figure>
	
	
	<p class="title_class_l_1"><span class="title_class_task">Task 8:</span> &nbsp; <span class="title_class_name">Photo Enhancement</p>
	<p class="desc_class_l_1_2"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">ResNet - 12 &nbsp; | &nbsp; <span class="mode">CPU, NPU, DSP</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">128 x 192 px</p>
	<p class="desc_class_l_2"><span class="desc_class_name">DPED PSNR i-Score:</span> &nbsp; <span class="desc_class_value">18.11 dB</p>
	<p class="desc_class_l_2"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="http://dped-photos.vision.ee.ethz.ch" target="_blank">paper</a> / <a href="http://people.ee.ethz.ch/~ihnatova/wespe.html" target="_blank">paper</a> / <a href="https://github.com/aiff22/dped" target="_blank">code</a></p>
	<p class="desc_class_l_4_2"> Still struggling when looking at photos from your old phone? This can be fixed: a properly trained neural network can make photos even from an ancient iPhone 3GS looking nice and up-to-date. To do this, it observes and learns how to transform photos from a low-quality device into the same photos from a DSLR camera. Of course there are some obvious limits for this magic (e.g. the network should be retrained for each new phone model), but the resulting images are looking quite good, especially for old devices.</p>

</div>

<!------------------------------ Task 9 ----------------------------->

<div class="task" style="margin-bottom: 1.2vw;">

	<img class="img_style_left_3" src="assets/img/screen_9.jpg">
	<p class="title_class_1"><span class="title_class_task">Task 9:</span> &nbsp; <span class="title_class_name">Memory Limits</p>
	<p class="desc_class_1"><span class="desc_class_name">Neural Network:</span> &nbsp; <span class="desc_class_value">SRCNN 9-5-5 &nbsp; | &nbsp; <span class="mode">CPU, NPU, DSP</p>	
	<p class="desc_class_2"><span class="desc_class_name">Image Resolution:</span> &nbsp; <span class="desc_class_value">4 MP</p>
	<p class="desc_class_2"><span class="desc_class_name"># Parameters:</span> &nbsp; <span class="desc_class_value">69.162</p>
	<p class="desc_class_3"><span class="desc_class_name">Paper & Code Links:</span> &nbsp; <span class="desc_class_value"><a href="https://arxiv.org/pdf/1501.00092.pdf" target="_blank">paper</a> / <a href="http://mmlab.ie.cuhk.edu.hk/projects/SRCNN.html" target="_blank">code</a></p>
	<p class="desc_class_4"> You should already recognize it from task 4: SRCNN, one of the lightest and simplest neural networks... But even it can bring the majority of phones to their knees while handling high-resolution photos: to process HD-images the phone should generally have at least 6GB of RAM. This test is aimed at finding the limits of your device: how large images can it handle with this simplest network? </p>

</div>

</div>

<div id="about">
	<div id="content">
		<p >Copyright © 2018 by A.I.</p>
		<p style="color: #ea1d6f">ETH Zurich, Switzerland</p>
	</div>
</div>

<script src="js/jquery-2.1.1.js"></script>
<script src="js/jquery.mobile.custom.min.js"></script>
<script src="js/main.js"></script>

</body>

</html>
